---
title: "SoulGuard: A Data-Driven Approach to Preventing Depression-Induced Suicide Through Social Media Analysis"
subtitle: "INFO 698 - Capstone Project"
author:
  - name: "SoulGuard - Arun, Anusha, Mrunal, Sachin, Tushar"
    affiliations: 
      - name: "College of Information Science, University of Arizona"
description: "This project aims to develop an AI-driven platform that ethically analyzes social media posts to identify signs of depression and provides personalized interventions to prevent suicide."
format:
   html:
    code-tools: true
    code-overflow: wrap
    embed-resources: true
editor: visual
execute:
  warning: false
---

```{r}
#| label: load-packages
#| include: false
#| warning: FALSE
#| echo: FALSE

# Load packages here
pacman::p_load(dplyr,
               ggplot2,
               ggridges,
               scales,
               patchwork,
               stringr,
               tidyr,
               kableExtra,
               plotly,
               maps,
               ggrepel,
               animation,
               gganimate,
               utiles,
               RColorBrewer)
```

```{r}
#| label: load-dataset
#| message: false
#| warning: FALSE
#| echo: FALSE

# Load in the datasets
Suicide_Detection <- read.csv("C:/Users/diput/Documents/GitHub/SoulGuard/data/Suicide_Detection.csv", na.strings = "")
SoulG_Cleaned_Data_SoulG <- read.csv("C:/Users/diput/Documents/GitHub/SoulGuard/data/SoulG_Update.csv")
Worrying_Words <- read.csv("C:/Users/diput/Documents/GitHub/SoulGuard/data/worrywords-v1.csv")

```

## Abstract

The objective of this project is to develop an AI-powered application designed to analyze social media posts for signs of depression using advanced data analysis and ethical AI techniques.

By detecting early indicators, the application will provide personalized interventions, including uplifting resources and mental health support suggestions, to users in need.

The project emphasizes privacy, ethical considerations, and user-centric design to foster a compassionate platform that promotes mental well-being and suicide prevention.

## Introduction

Mental health issues and depression are significant challenges in today's digital age, with social media platforms often serving as both a reflection of personal struggles and a space for self-expression. However, identifying early signs of depression can be difficult due to the vast and unstructured nature of online data. Suicide prevention requires timely intervention, and the gap between recognizing and addressing mental health risks continues to be a critical societal concern.

To address this, SoulGuard leverages advanced artificial intelligence to analyze social media posts ethically, detecting early indications of depression while preserving user privacy. The project draws on psychological research, machine learning techniques, and natural language processing to provide meaningful insights and personalized interventions aimed at suicide prevention. By combining data-driven analysis with user-focused design, SoulGuard aspires to foster a supportive environment for individuals at risk.

This project utilizes anonymized social media datasets, enriched with metadata that captures user demographics, sentiment trends, and linguistic patterns associated with mental health. It integrates models fine-tuned for sentiment analysis, topic modeling, and predictive risk assessment, ensuring precise and actionable outcomes.

Through this initiative, SoulGuard seeks to advance the conversation around ethical AI applications in mental health, promoting emotional well-being and empowering individuals with timely and personalized support resources.

## Methodology

## Data Collection and Preprocessing

-   We collected raw `Suicide_Detection` data from the internet, consisting of three columns: an unnamed column containing random numbers, a `text` column with post data from social media that includes unnecessary text and symbols, and a `class` column. This dataset required significant cleaning to prepare it for analysis.

```{r}
#| label: display-suicide-detection
#| echo: false
#| message: false
#| warning: false

# Load the Suicide_Detection dataset
Suicide_Detection <- read.csv("C:/Users/diput/Documents/GitHub/SoulGuard/data/Suicide_Detection.csv", na.strings = "")

# Display all columns, with the text column limited to 75 characters in a nice table
library(dplyr)
library(knitr)

Suicide_Detection %>%
  mutate(text = substr(text, 1, 75)) %>%  # Truncate the 'text' column to 75 characters
  head(10) %>%  # Display first 10 rows
  kable(col.names = c("Unnamed", "Text", "Class"), 
        caption = "Sample of the Suicide Detection Dataset (Text Truncated to 75 Characters)")

```

-   During the cleaning of the raw data, we removed unnecessary columns such as the unnamed column, cleaned the text column by removing characters and unnecessary strings, and added a new column to count the word length.

```{r}
#| label: display-top-10
#| echo: false
#| message: false
#| warning: false

library(dplyr)
library(stringr)
library(knitr)

# Display the first 10 rows of selected columns with truncated text in a nice table
SoulG_Cleaned_Data_SoulG %>%
  mutate(
    text = str_trunc(text, 75),  # Truncate 'text' column to 25 characters
    cleaned_text = str_trunc(cleaned_text, 75)  # Truncate 'cleaned_text' column to 25 characters
  ) %>%
  select(cleaned_text, class, wordlength) %>%
  head(10) %>%
  kable(
    col.names = c("Cleaned Text (Truncated)", "Class", "Word Length"),
    caption = "Sample of SoulGuard Cleaned Data with Truncated Text Columns"
  )

```

-   The Worrying Words dataset has been successfully integrated into the model to enhance its ability to identify and analyze patterns indicative of depressive language.

```{r}
#| label: load-worrying-words
#| echo: false
#| message: false
#| warning: false

library(knitr)

# Load the Worrying_Words dataset
Worrying_Words <- read.csv("C:/Users/diput/Documents/GitHub/SoulGuard/data/worrywords-v1.csv")

# Display the first few rows of the dataset in a nice table
head(Worrying_Words, 10) %>%
  kable(
    col.names = c("Term", "Mean", "OrdinalClass", "MajorityLabel", "MajorityLabelRatio", "NumberAnnotations", "SetOfLabels"),  # Adjust column names if necessary
    caption = "Sample of Worrying Words Dataset"
  )



```

## Model Selection and Training

-   Pre-trained natural language processing models (e.g., BERT, RoBERTa) will be fine-tuned for sentiment analysis and depression detection.\
-   Additional machine learning models will analyze trends and generate predictive risk assessments.

## Intervention Framework

-   The platform will integrate personalized interventions, such as connecting users to mental health resources, generating uplifting content, or providing anonymous tips to their support network.

## Ethical Considerations

-   Strict adherence to ethical AI practices will guide the project's development, ensuring data privacy and user consent.

## Evaluation and Validation

-   Model performance will be validated through metrics such as accuracy, precision, recall, and F1-score.\
-   Feedback from mental health professionals will be incorporated to refine the intervention mechanisms.

By employing this methodology, SoulGuard aims to balance technological innovation with sensitivity to user needs, creating a solution that is both impactful and responsible.

This is a Quarto website.

To learn more about Quarto websites visit <https://quarto.org/docs/websites>.
